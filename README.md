# üõí Olist E-Commerce End-to-End Lakehouse Project

![Databricks](https://img.shields.io/badge/Databricks-FF3621?style=for-the-badge&logo=databricks&logoColor=white)
![Spark](https://img.shields.io/badge/Apache%20Spark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)

> **X√¢y d·ª±ng Data Lakehouse chu·∫©n Production tr√™n Databricks s·ª≠ d·ª•ng ki·∫øn tr√∫c Medallion, Spark Structured Streaming v√† Unity Catalog.**

---

## üìã 1. T·ªïng Quan D·ª± √Ån (Project Overview)

D·ª± √°n n√†y x√¢y d·ª±ng m·ªôt pipeline d·ªØ li·ªáu hi·ªán ƒë·∫°i (Modern Data Pipeline) ƒë·ªÉ x·ª≠ l√Ω b·ªô d·ªØ li·ªáu th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ n·ªïi ti·∫øng **Brazilian E-Commerce Public Dataset by Olist**.

**M·ª•c ti√™u ch√≠nh:**
Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu giao d·ªãch th√¥ (Raw CSV) th√†nh c√°c th√¥ng tin chi ti·∫øt c√≥ gi√° tr·ªã kinh doanh (Business Insights) ƒë·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi:
* Doanh thu thay ƒë·ªïi nh∆∞ th·∫ø n√†o theo th·ªùi gian?
* Danh m·ª•c s·∫£n ph·∫©m n√†o b√°n ch·∫°y nh·∫•t?
* Ph√¢n b·ªë ƒë·ªãa l√Ω c·ªßa kh√°ch h√†ng ra sao?

---

## üèó 2. Ki·∫øn Tr√∫c H·ªá Th·ªëng (Architecture)

D·ª± √°n √°p d·ª•ng ki·∫øn tr√∫c **Medallion (Multi-hop)** ƒë∆∞·ª£c qu·∫£n tr·ªã b·ªüi **Unity Catalog**:

1.  **Bronze Layer (Raw):** Ingest d·ªØ li·ªáu th√¥ t·ª´ CSV, gi·ªØ nguy√™n l·ªãch s·ª≠, s·ª≠ d·ª•ng **Auto Loader**.
2.  **Silver Layer (Cleansed):** L√†m s·∫°ch d·ªØ li·ªáu, chu·∫©n h√≥a Schema.
    * √Åp d·ª•ng **SCD Type 2** cho c√°c b·∫£ng Dimension (Customers, Sellers, Products).
    * √Åp d·ª•ng **Streaming Deduplication** cho c√°c b·∫£ng Fact.
3.  **Gold Layer (Curated):** D·ªØ li·ªáu t·ªïng h·ª£p (Aggregated) theo m√¥ h√¨nh Star Schema, t·ªëi ∆∞u cho b√°o c√°o.
4.  **Business Layer:** C√°c View ph·ª•c v·ª• tr·ª±c ti·∫øp cho Dashboard.

![System Architecture](screenshot/ETL.png)

---

## üõ† 3. C√¥ng Ngh·ªá S·ª≠ D·ª•ng (Tech Stack)

* **Cloud Platform:** Databricks on AWS/Azure.
* **Core Engine:** Apache Spark (Structured Streaming), Delta Lake.
* **Orchestration:** Databricks Workflows.
* **Governance:** Unity Catalog (Lineage, Access Control).
* **DevOps:** Git Integration (CI/CD basics).
* **Visualization:** Databricks SQL Dashboard.

---

## üöÄ 4. Chi Ti·∫øt K·ªπ Thu·∫≠t (Key Features)

### 4.1. Ingestion Layer (Raw to Bronze)
S·ª≠ d·ª•ng **Auto Loader (`cloudFiles`)** ƒë·ªÉ gi·∫£i quy·∫øt b√†i to√°n Ingestion t·ª± ƒë·ªông:
* T·ª± ƒë·ªông ph√°t hi·ªán file m·ªõi trong Volume.
* **Schema Evolution:** T·ª± ƒë·ªông th√≠ch ·ª©ng khi c·∫•u tr√∫c file ngu·ªìn thay ƒë·ªïi (th√™m c·ªôt m·ªõi).
* Th√™m metadata `_source_file` v√† `_ingested_at` ƒë·ªÉ truy v·∫øt ngu·ªìn g·ªëc.

### 4.2. Transformation Layer (Bronze to Silver)
ƒê√¢y l√† ph·∫ßn x·ª≠ l√Ω ph·ª©c t·∫°p nh·∫•t v·ªõi logic nghi·ªáp v·ª• cao c·∫•p:

* **Slowly Changing Dimension (SCD) Type 2:**
    * Theo d√µi l·ªãch s·ª≠ thay ƒë·ªïi c·ªßa kh√°ch h√†ng/s·∫£n ph·∫©m.
    * Logic: ƒê√≥ng d√≤ng c≈© (`is_current=false`, update `end_date`) -> M·ªü d√≤ng m·ªõi (`is_current=true`).
    * Code tham kh·∫£o: `utils/scd_handler.py`.

* **Data Quality Checks:**
    * L·ªçc b·ªè d·ªØ li·ªáu r√°c (V√≠ d·ª•: Gi√° tr·ªã ƒë∆°n h√†ng < 0, ID b·ªã Null) ngay t·∫°i ƒë·∫ßu v√†o Silver.

### 4.3. Orchestration (Databricks Workflows)
To√†n b·ªô quy tr√¨nh ƒë∆∞·ª£c t·ª± ƒë·ªông h√≥a, ƒë·∫£m b·∫£o t√≠nh ph·ª• thu·ªôc gi·ªØa c√°c task.

![Pipeline Workflow](screenshot/Pipeline.png)
*(H√¨nh ·∫£nh: Pipeline ch·∫°y th√†nh c√¥ng t·ª´ Bronze ƒë·∫øn Gold)*

---

## üìä 5. K·∫øt Qu·∫£ Ph√¢n T√≠ch (Analytics & Monitoring)

### 5.1. Business Dashboard
Dashboard tr·ª±c quan gi√∫p theo d√µi s·ª©c kh·ªèe doanh nghi·ªáp theo th·ªùi gian th·ª±c.

**Xu h∆∞·ªõng Doanh thu & L∆∞·ª£ng ƒë∆°n h√†ng:**
![Revenue Trend](screenshot/MonthlyRevenue&OrderVolume.png)

**Top Danh m·ª•c s·∫£n ph·∫©m b√°n ch·∫°y:**
![Top Categories](screenshot/BestSellingCategories.png)

**B·∫£n ƒë·ªì ph√¢n b·ªï doanh thu theo Bang:**
![Geo Map](screenshot/RevenueSharebyState(TopMarkets).png)

### 5.2. H·ªá th·ªëng C·∫£nh b√°o (Alerts)
H·ªá th·ªëng t·ª± ƒë·ªông gi√°m s√°t v√† g·ª≠i c·∫£nh b√°o qua Email khi c√≥ b·∫•t th∆∞·ªùng (V√≠ d·ª•: Doanh thu gi·∫£m s√¢u so v·ªõi trung b√¨nh qu√° kh·ª©).

![Alert System](screenshot/Alert.png)

---

## üìÇ 6. C·∫•u Tr√∫c D·ª± √Ån (Project Structure)

```text
databricks-medallion-ecommerce/
‚îú‚îÄ‚îÄ pipelines/                  # M√£ ngu·ªìn ETL ch√≠nh (Notebooks)
‚îÇ   ‚îú‚îÄ‚îÄ 00_initialize/          # Setup Catalog & Schema
‚îÇ   ‚îú‚îÄ‚îÄ 01_bronze_ingestion/    # Raw -> Bronze (Auto Loader)
‚îÇ   ‚îú‚îÄ‚îÄ 02_silver_transformation/# Bronze -> Silver (SCD2, Streaming)
‚îÇ   ‚îî‚îÄ‚îÄ 03_gold_aggregation/    # Silver -> Gold (Aggregates)
‚îú‚îÄ‚îÄ utils/                      # C√°c h√†m d√πng chung (Reusable Functions)
‚îÇ   ‚îú‚îÄ‚îÄ scd_handler.py          # Class x·ª≠ l√Ω SCD Type 2 Logic
‚îÇ   ‚îî‚îÄ‚îÄ spark_utils.py          # Class x·ª≠ l√Ω Auto Loader
‚îú‚îÄ‚îÄ tests/                      # Unit Test & Integration Test (SQL checks)
‚îú‚îÄ‚îÄ screenshot/                 # H√¨nh ·∫£nh minh h·ªça cho README
‚îî‚îÄ‚îÄ README.md                   # T√†i li·ªáu d·ª± √°n
```

## üèÅ 7. H∆∞·ªõng D·∫´n C√†i ƒê·∫∑t (How to Run)

ƒê·ªÉ tri·ªÉn khai d·ª± √°n n√†y tr√™n m√¥i tr∆∞·ªùng Databricks c·ªßa b·∫°n, h√£y l√†m theo c√°c b∆∞·ªõc sau:

### B∆∞·ªõc 1: Chu·∫©n b·ªã M√¥i tr∆∞·ªùng
* ƒê·∫£m b·∫£o b·∫°n c√≥ **Databricks Workspace** v·ªõi **Unity Catalog** ƒë√£ ƒë∆∞·ª£c k√≠ch ho·∫°t.
* T·∫°o **Compute Cluster** v·ªõi Runtime t·ªëi thi·ªÉu **13.3 LTS**.

### B∆∞·ªõc 2: Setup D·ªØ li·ªáu
1.  T·∫£i b·ªô d·ªØ li·ªáu **Olist** t·ª´ Kaggle.
2.  T·∫°o Volume trong Unity Catalog ƒë·ªÉ ch·ª©a d·ªØ li·ªáu th√¥:
    ```sql
    CREATE CATALOG IF NOT EXISTS olist_catalog;
    CREATE SCHEMA IF NOT EXISTS olist_catalog.bronze;
    CREATE VOLUME IF NOT EXISTS olist_catalog.bronze.raw_data;
    ```
3.  Upload c√°c file CSV v√†o ƒë∆∞·ªùng d·∫´n: `/Volumes/olist_catalog/bronze/raw_data/`.

### B∆∞·ªõc 3: Deploy Code
1.  V√†o **Databricks Workspace** -> **Git Folders**.
2.  Clone repository n√†y v·ªÅ.

### B∆∞·ªõc 4: Ch·∫°y Pipeline
1.  Ch·∫°y Notebook `pipelines/00_initialize/setup_catalog.sql` ƒë·ªÉ kh·ªüi t·∫°o database.
2.  V√†o m·ª•c **Workflows**, t·∫°o m·ªôt **Job** m·ªõi v·ªõi c√°c Task n·ªëi ti·∫øp nhau:
    * **Task 1:** `01_bronze_ingestion`
    * **Task 2:** `02_silver_transformation` (Dependent on Task 1)
    * **Task 3:** `03_gold_aggregation` (Dependent on Task 2)
3.  Nh·∫•n **Run Now** v√† theo d√µi qu√° tr√¨nh x·ª≠ l√Ω.

---

## üåü 8. ƒê·ªãnh H∆∞·ªõng Ph√°t Tri·ªÉn (Future Improvements)

Do gi·ªõi h·∫°n v·ªÅ th·ªùi gian, d·ª± √°n n√†y t·∫≠p trung v√†o Data Engineering c·ªët l√µi. Trong t∆∞∆°ng lai, h·ªá th·ªëng c√≥ th·ªÉ ƒë∆∞·ª£c m·ªü r·ªông theo c√°c h∆∞·ªõng sau:

### 1. N√¢ng cao Ch·∫•t l∆∞·ª£ng D·ªØ li·ªáu (DQX)
* T√≠ch h·ª£p **Delta Live Tables (DLT)** ƒë·ªÉ qu·∫£n l√Ω pipeline thay v√¨ d√πng Job th√¥ng th∆∞·ªùng.
* S·ª≠ d·ª•ng **DLT Expectations** ƒë·ªÉ ch·∫∑n d·ªØ li·ªáu l·ªói (Quarantine) thay v√¨ ch·ªâ l·ªçc b·ªè.

### 2. Machine Learning & Forecasting
* S·ª≠ d·ª•ng d·ªØ li·ªáu ·ªü Gold Layer ƒë·ªÉ train model d·ª± ƒëo√°n doanh thu (**Time Series Forecasting**) d√πng th∆∞ vi·ªán Prophet.
* Ph√¢n c·ª•m kh√°ch h√†ng (**Customer Segmentation**) ƒë·ªÉ ch·∫°y c√°c chi·∫øn d·ªãch Marketing.

### 3. CI/CD & Automation
* S·ª≠ d·ª•ng **Databricks Asset Bundles (DABs)** ƒë·ªÉ ƒë√≥ng g√≥i v√† deploy d·ª± √°n t·ª± ƒë·ªông.
* T√≠ch h·ª£p **GitHub Actions** ƒë·ªÉ ch·∫°y Unit Test m·ªói khi merge code.

---
> **Author:** Student at HUST (Hanoi University of Science and Technology)  
> **Course:** Databricks Data Engineering Bootcamp
